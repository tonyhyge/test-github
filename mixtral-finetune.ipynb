{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyhyge/test-github/blob/main/mixtral-finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4727adb-7646-4397-aaf8-f1d8a702b540",
      "metadata": {
        "id": "e4727adb-7646-4397-aaf8-f1d8a702b540"
      },
      "source": [
        "<!-- Banner Image -->\n",
        "<img src=\"https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brev-xmas-3.png\" width=\"100%\">\n",
        "\n",
        "<!-- Links -->\n",
        "<center>\n",
        "  <a href=\"https://console.brev.dev\" style=\"color: #06b6d4;\">Console</a> â€¢\n",
        "  <a href=\"https://brev.dev\" style=\"color: #06b6d4;\">Docs</a> â€¢\n",
        "  <a href=\"/\" style=\"color: #06b6d4;\">Templates</a> â€¢\n",
        "  <a href=\"https://discord.gg/NVDyv7TUgJ\" style=\"color: #06b6d4;\">Discord</a>\n",
        "</center>\n",
        "\n",
        "# Fine-tuning Mixtral 8x7B using QLoRA ðŸ¤™\n",
        "\n",
        "Welcome!\n",
        "\n",
        "In this notebook and tutorial, we will fine-tune the [Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1) Mixture of Experts (MoE) model, which outperforms Llama 2 70B on most tested benchmarks.\n",
        "\n",
        "No A100 needed!\n",
        "\n",
        "**Watch an accompanying video walk-through (but for Mistral 7B and using your own data, but the notebook is very similar) [here](https://youtu.be/kmkcNVvEz-k?si=Ogt1wRFNqYI6zXfw&t=1)!** If you'd like to see that notebook instead, click [here](https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb). If you'd like to see a notebook to fine-tune Mistral's 8x7B MoE on **your own data**, click [here](https://github.com/brevdev/notebooks/blob/main/mixtral-finetune-own-data.ipynb).\n",
        "\n",
        "This tutorial will use QLoRA, a fine-tuning method that combines quantization and LoRA. For more information about what those are and how they work, see [this post](https://brev.dev/blog/how-qlora-works).\n",
        "\n",
        "In this notebook, we will load the large model in 4bit using `bitsandbytes` and use LoRA to train using the PEFT library from Hugging Face ðŸ¤—.\n",
        "\n",
        "Note that if you ever have trouble importing something from Huggingface, you may need to run `huggingface-cli login` in a shell. To open a shell in Jupyter Lab, click on 'Launcher' (or the '+' if it's not there) next to the notebook tab at the top of the screen. Under \"Other\", click \"Terminal\" and then run the command.\n",
        "\n",
        "### Help us make this tutorial better! Please provide feedback on the [Discord channel](https://discord.gg/y9428NwTh3) or on [X](https://x.com/harperscarroll)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b517cd3-4868-4961-9812-bc6746d4e1fc",
      "metadata": {
        "id": "6b517cd3-4868-4961-9812-bc6746d4e1fc"
      },
      "source": [
        "### 1. Instantiate GPU\n",
        "\n",
        "I used a GPU and dev environment from [brev.dev](https://brev.dev). Click the badge below to get your preconfigured instance:\n",
        "\n",
        "[![ Click here to deploy.](https://brev-assets.s3.us-west-1.amazonaws.com/nv-lb-dark.svg)](https://console.brev.dev/environment/new?instance=T4:g4dn.12xlarge&diskStorage=512&name=mixtral-finetune&file=https://github.com/brevdev/notebooks/raw/main/mixtral-finetune.ipynb&python=3.10&cuda=12.0.1)\n",
        "\n",
        "A 4xT4 (as linked) with 16 GPU Memory per GPU was enough for me. At the time of writing this, it costs $3.91/hour, and it trained for about 2 hours for 100 training steps. You may need more GPUs and/or Memory if your sequence max_length is larger than 320 (you'll read more about this below).\n",
        "\n",
        "Once you've checked out your machine and landed in your instance page, select the specs you'd like (I used **Python 3.10 and CUDA 12.0.1**; these should be preconfigured for you if you use the badge above) and click the \"Build\" button to build your verb container. Give this a few minutes.\n",
        "\n",
        "A few minutes after your model has started Running, click the 'Notebook' button on the top right of your screen once it illuminates (you may need to refresh the screen). You will be taken to a Jupyter Lab environment, where you can upload this Notebook.\n",
        "\n",
        "\n",
        "Note: You can connect your cloud credits (AWS or GCP) by clicking \"Org: \" on the top right, and in the panel that slides over, click \"Connect AWS\" or \"Connect GCP\" under \"Connect your cloud\" and follow the instructions linked to attach your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1feb7b-fa55-48b5-ab64-8822ae97875a",
      "metadata": {
        "id": "2d1feb7b-fa55-48b5-ab64-8822ae97875a",
        "outputId": "a39e2168-32a1-4eb6-d65c-6a683386c8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# You only need to run this once per machine, even if you stop/restart it\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sb21TxJsbJAa"
      },
      "id": "Sb21TxJsbJAa"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MTsox-_fbI-Q"
      },
      "id": "MTsox-_fbI-Q"
    },
    {
      "cell_type": "markdown",
      "id": "8d3cb0d0-1063-4691-8244-6dce1733f517",
      "metadata": {
        "id": "8d3cb0d0-1063-4691-8244-6dce1733f517"
      },
      "source": [
        "Let's use Weights & Biases to track our training metrics. You'll need to apply an API key when prompted. Feel free to skip this if you'd like, and just comment out the `wandb` parameters in the `Trainer` definition below.\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be378315-c391-4f7f-8db3-b1442387cc62",
      "metadata": {
        "id": "be378315-c391-4f7f-8db3-b1442387cc62"
      },
      "source": [
        "### 3. Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece42f7c-3825-45c7-9afc-efb355e9474c",
      "metadata": {
        "id": "ece42f7c-3825-45c7-9afc-efb355e9474c"
      },
      "source": [
        "Let's load a meaning representation dataset, and fine-tune Mixtral on that. This is a great fine-tuning dataset as it teaches the model a unique form of desired output on which the base model performs poorly out-of-the box, so it's helpful to easily and inexpensively gauge whether the fine-tuned model has learned well. (Sources: [here](https://ragntune.com/blog/gpt3.5-vs-llama2-finetuning) and [here](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts)) (In contrast, if you fine-tune on a fact-based dataset, the model may already do quite well on that, and gauging learning is less obvious / may be more computationally expensive.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb30bec2-199d-46ee-99ac-0c47fecb6c87",
      "metadata": {
        "id": "eb30bec2-199d-46ee-99ac-0c47fecb6c87"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('gem/viggo', split='train')\n",
        "eval_dataset = load_dataset('gem/viggo', split='validation')\n",
        "test_dataset = load_dataset('gem/viggo', split='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ab8440-a2c5-4450-9095-5a18da3e80b9",
      "metadata": {
        "id": "75ab8440-a2c5-4450-9095-5a18da3e80b9",
        "scrolled": true,
        "outputId": "595d0f59-dfaf-4816-923b-fd3c6de9d6db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['gem_id', 'meaning_representation', 'target', 'references'],\n",
            "    num_rows: 5103\n",
            "})\n",
            "Dataset({\n",
            "    features: ['gem_id', 'meaning_representation', 'target', 'references'],\n",
            "    num_rows: 714\n",
            "})\n",
            "Dataset({\n",
            "    features: ['gem_id', 'meaning_representation', 'target', 'references'],\n",
            "    num_rows: 1083\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)\n",
        "print(eval_dataset)\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97961855-bec0-4b3b-ab0e-c013a329de75",
      "metadata": {
        "id": "97961855-bec0-4b3b-ab0e-c013a329de75"
      },
      "source": [
        "### 4. Load Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26071032-245a-4305-85f2-c2eda775d626",
      "metadata": {
        "id": "26071032-245a-4305-85f2-c2eda775d626"
      },
      "source": [
        "Sheesh, I spent all this time figuring out how to torrent from this notebook but alas, now Mistral's 8x7B MoE model is on Hugging Face. So we're just gonna load it from there.\n",
        "\n",
        "We're also gonna load it in 4-bit quantization.\n",
        "I wanted to load in 8-bit quantization but ran into this bug: https://github.com/TimDettmers/bitsandbytes/issues/736. If you find a way to resolve this, I'll give you GPU credits!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2dfb4bf-885d-4f21-b3c8-01a3a705a60f",
      "metadata": {
        "id": "f2dfb4bf-885d-4f21-b3c8-01a3a705a60f",
        "scrolled": true,
        "outputId": "d654598d-d9d3-482c-cf1a-d5a16c011592",
        "colab": {
          "referenced_widgets": [
            "abda8b86f7a34443bada0a37a70a7723"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abda8b86f7a34443bada0a37a70a7723",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01769f1-79a0-4f97-9867-32f065e14751",
      "metadata": {
        "id": "b01769f1-79a0-4f97-9867-32f065e14751"
      },
      "source": [
        "### 5. Tokenization\n",
        "\n",
        "Set up the tokenizer.\n",
        "\n",
        "To set `max_length`, which has a direct impact on your compute requirements, it's helpful to get a distribution of your data lengths. Hugging Face shares that data clearly, like so:\n",
        "\n",
        "![image.png](attachment:77593312-b2b3-4238-891b-417930e2e9b9.png)\n",
        "\n",
        "However, since we're combining multiple features of this dataset in `generate_and_tokenize_prompt`, let's get our own distribution of the final form of the data. Let's first tokenize without the truncation/padding, so we can get that length distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f07ce53-a4cf-49d7-85d2-dcff316dec09",
      "metadata": {
        "id": "6f07ce53-a4cf-49d7-85d2-dcff316dec09"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca1a7057-ed43-42c0-a3dd-3e69515aa709",
      "metadata": {
        "id": "ca1a7057-ed43-42c0-a3dd-3e69515aa709"
      },
      "source": [
        "Setup the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e689a62-d15a-4da6-9c69-0d4c7020e979",
      "metadata": {
        "id": "7e689a62-d15a-4da6-9c69-0d4c7020e979"
      },
      "outputs": [],
      "source": [
        "def tokenize(prompt):\n",
        "    result = tokenizer(prompt)\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c86958cc-9443-4b56-adb4-540f97aad84b",
      "metadata": {
        "id": "c86958cc-9443-4b56-adb4-540f97aad84b"
      },
      "source": [
        "And convert each sample into a prompt that I found from [this notebook](https://github.com/samlhuillier/viggo-finetune/blob/main/llama/fine-tune-code-llama.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16792cd-cfbb-4503-9af9-32560af83ec4",
      "metadata": {
        "id": "c16792cd-cfbb-4503-9af9-32560af83ec4"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt =f\"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "{data_point[\"target\"]}\n",
        "\n",
        "### Meaning representation:\n",
        "{data_point[\"meaning_representation\"]}\n",
        "\"\"\"\n",
        "    return tokenize(full_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9329f2-054c-4dd3-b446-e2483210dcaa",
      "metadata": {
        "id": "ae9329f2-054c-4dd3-b446-e2483210dcaa"
      },
      "source": [
        "Reformat the prompt and tokenize each sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d712589-bf73-4b81-8e23-f178416d1ebd",
      "metadata": {
        "id": "6d712589-bf73-4b81-8e23-f178416d1ebd",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a489de-9060-4c37-91ea-160caf3ec01c",
      "metadata": {
        "id": "c0a489de-9060-4c37-91ea-160caf3ec01c"
      },
      "source": [
        "You can untokenize to make sure it was formatted properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308f9d42-0315-413d-99a2-1745f94159ba",
      "metadata": {
        "id": "308f9d42-0315-413d-99a2-1745f94159ba",
        "outputId": "c7213b5d-faf8-4267-827b-819671958d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Dirt: Showdown is a sport racing game that was released in 2012. The game is available on PlayStation, Xbox, and PC, and it has an ESRB Rating of E 10+ (for Everyone 10 and Older). However, it is not yet available as a Steam, Linux, or Mac release.\n",
            "\n",
            "### Meaning representation:\n",
            "inform(name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no])\n",
            "</s>\n"
          ]
        }
      ],
      "source": [
        "untokenized_text = tokenizer.decode(tokenized_train_dataset[1]['input_ids'])\n",
        "print(untokenized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe974dc-4d06-4a61-a5e5-db191c92c965",
      "metadata": {
        "id": "0fe974dc-4d06-4a61-a5e5-db191c92c965"
      },
      "source": [
        "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a94ba3-95d1-4e53-bb03-96215f68e126",
      "metadata": {
        "id": "c6a94ba3-95d1-4e53-bb03-96215f68e126",
        "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5817\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b23cc8d-68f2-4230-8a75-330a490d39b0",
      "metadata": {
        "id": "4b23cc8d-68f2-4230-8a75-330a490d39b0"
      },
      "source": [
        "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
        "\n",
        "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning).\n",
        "\n",
        "Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a293be61-6b90-4da7-933e-1679a1d1220c",
      "metadata": {
        "id": "a293be61-6b90-4da7-933e-1679a1d1220c"
      },
      "outputs": [],
      "source": [
        "max_length = 340 # This was an appropriate max length for my dataset\n",
        "\n",
        "# redefine the tokenize function and tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    padding_side=\"left\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def tokenize(prompt):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2667459f-fca0-480c-9934-f3b9a7b6361b",
      "metadata": {
        "id": "2667459f-fca0-480c-9934-f3b9a7b6361b"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5238ada4-5ed9-4970-a594-932663f77282",
      "metadata": {
        "id": "5238ada4-5ed9-4970-a594-932663f77282"
      },
      "source": [
        "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b915cd9-d26f-44c4-95ce-d979b34f60be",
      "metadata": {
        "id": "0b915cd9-d26f-44c4-95ce-d979b34f60be",
        "scrolled": true,
        "outputId": "535f3009-b568-4398-a746-70f6f0988b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 12628, 264, 2718, 12271, 5122, 272, 14164, 5746, 9283, 302, 272, 2787, 12271, 390, 264, 2692, 908, 395, 9623, 304, 6836, 3069, 28723, 13, 3260, 908, 1023, 6685, 272, 2718, 1423, 24329, 304, 272, 908, 1580, 347, 624, 302, 272, 2296, 5936, 262, 674, 647, 464, 3134, 647, 464, 28721, 495, 28730, 410, 262, 296, 647, 464, 19928, 647, 464, 14876, 28730, 9122, 647, 464, 28713, 16939, 647, 464, 3134, 28730, 720, 11009, 352, 647, 464, 267, 1805, 416, 647, 464, 3134, 28730, 9122, 14303, 13, 1014, 9623, 1580, 347, 624, 302, 272, 2296, 28747, 5936, 861, 647, 464, 5128, 28730, 11023, 28730, 1408, 647, 464, 11023, 28730, 4395, 647, 464, 16239, 263, 647, 464, 274, 9312, 647, 464, 28599, 647, 464, 2383, 411, 647, 464, 7449, 28730, 4837, 8524, 647, 464, 3537, 28730, 13102, 7449, 647, 464, 10470, 28713, 647, 464, 13952, 28730, 266, 28730, 2453, 314, 647, 464, 3537, 28730, 8502, 28730, 11023, 647, 464, 3537, 28730, 7502, 28730, 11023, 647, 464, 4101, 3591, 1421, 13, 13, 27332, 15255, 12271, 28747, 13, 3195, 28742, 28713, 272, 1080, 9783, 2039, 369, 368, 4226, 297, 272, 879, 28705, 28750, 28734, 28740, 28781, 28804, 13, 13, 27332, 11736, 288, 9283, 28747, 13, 3134, 28732, 11023, 28730, 4395, 28792, 28750, 28734, 28740, 28781, 1181, 1229, 3591, 28792, 360, 7030, 2803, 13, 2]\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_train_dataset[4]['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b8b4c5a-93f6-41b8-951d-f1997adcdb46",
      "metadata": {
        "id": "0b8b4c5a-93f6-41b8-951d-f1997adcdb46"
      },
      "source": [
        "You can also untokenize to see it in plain text. It should start with `<s>` and end with `</s>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7ea587-9d43-48e3-8d6a-6c8bdb0a96e0",
      "metadata": {
        "scrolled": true,
        "id": "6c7ea587-9d43-48e3-8d6a-6c8bdb0a96e0",
        "outputId": "6d665ca4-ebca-4c6d-9746-7247b27e4bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s> Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Dirt: Showdown is a sport racing game that was released in 2012. The game is available on PlayStation, Xbox, and PC, and it has an ESRB Rating of E 10+ (for Everyone 10 and Older). However, it is not yet available as a Steam, Linux, or Mac release.\n",
            "\n",
            "### Meaning representation:\n",
            "inform(name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[</s>\n"
          ]
        }
      ],
      "source": [
        "untokenized_text = tokenizer.decode(tokenized_train_dataset[1]['input_ids'])\n",
        "print(untokenized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "648ed0fc-3b57-4523-b352-e70da097af74",
      "metadata": {
        "id": "648ed0fc-3b57-4523-b352-e70da097af74"
      },
      "source": [
        "Now all the samples should be the same length, `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01676d8f-4e82-48a6-a3ce-279651574983",
      "metadata": {
        "id": "01676d8f-4e82-48a6-a3ce-279651574983",
        "outputId": "c87e344d-e0f3-4542-afcc-4e2025926d64",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5817\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a2eb79-e9b8-4d29-9667-7be9bc3368b0",
      "metadata": {
        "id": "99a2eb79-e9b8-4d29-9667-7be9bc3368b0"
      },
      "source": [
        "#### How does the base model do?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe65c1a-62c2-4a36-99e3-3e972478261a",
      "metadata": {
        "id": "ffe65c1a-62c2-4a36-99e3-3e972478261a"
      },
      "source": [
        "Let's grab a test input (`meaning_representation`) and desired output (`target`) pair to see how the base model does on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f21bb8-e2df-4d76-bec4-bcbe966310c8",
      "metadata": {
        "id": "24f21bb8-e2df-4d76-bec4-bcbe966310c8",
        "scrolled": true,
        "outputId": "3d83e600-3705-4b70-e374-cf8401356396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target Sentence: Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
            "Meaning Representation: verify_attribute(name[Little Big Adventure], rating[average], has_multiplayer[no], platforms[PlayStation])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Target Sentence: \" + test_dataset[1]['target'])\n",
        "print(\"Meaning Representation: \" + test_dataset[1]['meaning_representation'] + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5020387-45b8-4a77-a63e-15cf6b1d8d5a",
      "metadata": {
        "id": "f5020387-45b8-4a77-a63e-15cf6b1d8d5a"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
        "\n",
        "### Meaning representation:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9866d9f-0578-4a61-8b13-f100a1a344ab",
      "metadata": {
        "id": "d9866d9f-0578-4a61-8b13-f100a1a344ab"
      },
      "outputs": [],
      "source": [
        "# Apply the accelerator. You can comment this out to remove the accelerator.\n",
        "model = accelerator.prepare_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b54d3b8e-88a6-4fbd-9375-509ea9a296af",
      "metadata": {
        "id": "b54d3b8e-88a6-4fbd-9375-509ea9a296af"
      },
      "outputs": [],
      "source": [
        "# Re-init the tokenizer so it doesn't add padding or eos token\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a253a4-a3a8-43b3-abb2-d602d8fa2ab0",
      "metadata": {
        "id": "93a253a4-a3a8-43b3-abb2-d602d8fa2ab0"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6f9452-0016-48f7-b355-588907eaff14",
      "metadata": {
        "id": "fb6f9452-0016-48f7-b355-588907eaff14",
        "outputId": "76ec22de-15a0-4588-dcc3-0e55cbf06958"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
            "\n",
            "### Meaning representation:\n",
            "inform(name(Little Big Adventure), has_multiplayer(Little Big Adventure))\n",
            "\n",
            "### Target sentence:\n",
            "I'm looking for a game that is available on Steam and has a multiplayer mode. Can you recommend any games that meet these criteria?\n",
            "\n",
            "### Meaning representation:\n",
            "request(name(game), has_multiplayer(game), available_on_steam(game))\n",
            "\n",
            "### Target sentence:\n",
            "I'm interested in a game that has a multiplayer mode and is available on Steam. Can you suggest any games that fit this description?\n",
            "\n",
            "### Mean\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=128)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6bc6c58-8338-4d5d-a8c0-05dfd7162423",
      "metadata": {
        "id": "f6bc6c58-8338-4d5d-a8c0-05dfd7162423"
      },
      "source": [
        "We can see it doesn't do very well out of the box."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c776579-4e4e-45d8-8c96-62cfb4293211",
      "metadata": {
        "id": "8c776579-4e4e-45d8-8c96-62cfb4293211"
      },
      "source": [
        "### 4. Set Up LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "682baafc-f687-493b-90fd-a7f384bad549",
      "metadata": {
        "id": "682baafc-f687-493b-90fd-a7f384bad549"
      },
      "source": [
        "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21874d9d-7adc-4dae-9aaa-76f81dc7ad75",
      "metadata": {
        "id": "21874d9d-7adc-4dae-9aaa-76f81dc7ad75"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "565c07b7-4670-4974-81c9-7c2dfc7a1d10",
      "metadata": {
        "id": "565c07b7-4670-4974-81c9-7c2dfc7a1d10"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f088a21-62b6-46e6-9323-2aa583754f4b",
      "metadata": {
        "id": "4f088a21-62b6-46e6-9323-2aa583754f4b"
      },
      "source": [
        "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `w1`, `w2`, `w3`, and `lm_head`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e477004-dbdb-4feb-82a0-681289522fdf",
      "metadata": {
        "id": "5e477004-dbdb-4feb-82a0-681289522fdf",
        "scrolled": true,
        "outputId": "f5447a1a-4b80-4c90-f8ca-27ee637dbd82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MixtralForCausalLM(\n",
            "  (model): MixtralModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MixtralDecoderLayer(\n",
            "        (self_attn): MixtralAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MixtralRotaryEmbedding()\n",
            "        )\n",
            "        (block_sparse_moe): MixtralSparseMoeBlock(\n",
            "          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
            "          (experts): ModuleList(\n",
            "            (0-7): 8 x MixtralBLockSparseTop2MLP(\n",
            "              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (input_layernorm): MixtralRMSNorm()\n",
            "        (post_attention_layernorm): MixtralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MixtralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630857be-801a-4586-a562-88ffc7772058",
      "metadata": {
        "id": "630857be-801a-4586-a562-88ffc7772058"
      },
      "source": [
        "Here we define the LoRA config.\n",
        "\n",
        "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
        "\n",
        "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
        "\n",
        "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=8` and `lora_alpha=16` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76ebe71-0bf2-4cdc-a20c-2a61bcebee1a",
      "metadata": {
        "id": "f76ebe71-0bf2-4cdc-a20c-2a61bcebee1a",
        "outputId": "30c5ebce-1379-42a9-ba7e-a0ab3a209a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 120350720 || all params: 23602952192 || trainable%: 0.5098968934945001\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"w1\",\n",
        "        \"w2\",\n",
        "        \"w3\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)\n",
        "\n",
        "# Apply the accelerator. You can comment this out to remove the accelerator.\n",
        "model = accelerator.prepare_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c9a52d-4c54-4f9b-8485-94a5033fe6d4",
      "metadata": {
        "id": "e2c9a52d-4c54-4f9b-8485-94a5033fe6d4"
      },
      "source": [
        "See how the model looks different now, with the LoRA adapters added:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787fdc11-ca63-4cac-8097-d533cedbd533",
      "metadata": {
        "id": "787fdc11-ca63-4cac-8097-d533cedbd533",
        "outputId": "1f14a4a8-472e-42d5-dae2-1c775e548055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): MixtralForCausalLM(\n",
            "      (model): MixtralModel(\n",
            "        (embed_tokens): Embedding(32000, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x MixtralDecoderLayer(\n",
            "            (self_attn): MixtralAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (rotary_emb): MixtralRotaryEmbedding()\n",
            "            )\n",
            "            (block_sparse_moe): MixtralSparseMoeBlock(\n",
            "              (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
            "              (experts): ModuleList(\n",
            "                (0-7): 8 x MixtralBLockSparseTop2MLP(\n",
            "                  (w1): lora.Linear4bit(\n",
            "                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.05, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=14336, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (w2): lora.Linear4bit(\n",
            "                    (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.05, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=14336, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=4096, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (w3): lora.Linear4bit(\n",
            "                    (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.05, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=14336, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (act_fn): SiLU()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (input_layernorm): MixtralRMSNorm()\n",
            "            (post_attention_layernorm): MixtralRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): MixtralRMSNorm()\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Dropout(p=0.05, inplace=False)\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=4096, out_features=8, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=8, out_features=32000, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eb4c7fe-c05a-479a-9208-84d86d22c0bf",
      "metadata": {
        "id": "9eb4c7fe-c05a-479a-9208-84d86d22c0bf"
      },
      "source": [
        "### 5. Run Training!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7599e90-27c6-461a-acfc-3c3a1e77cf4c",
      "metadata": {
        "id": "b7599e90-27c6-461a-acfc-3c3a1e77cf4c"
      },
      "source": [
        "I used 500 steps for the sake of getting this notebook out, but I found the model should have trained for longer as it had not converged by then, so I upped the steps to 1000 below. It may even need longer.\n",
        "\n",
        "A note on training. You can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting - the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir (`mistral-finetune-viggo`) as your final model in step 6 below.\n",
        "\n",
        "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d0aae4-60e2-4853-a949-1d2026c66e98",
      "metadata": {
        "id": "a9d0aae4-60e2-4853-a949-1d2026c66e98"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbb95a0-9f0f-465a-9657-506596615afb",
      "metadata": {
        "id": "edbb95a0-9f0f-465a-9657-506596615afb",
        "outputId": "76cb0e63-f636-4713-c008-b74a2a7cde41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.device_count() # should be 4 if using Brev's instance link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "832143f1-35a3-454c-82f9-42f195a03c8f",
      "metadata": {
        "id": "832143f1-35a3-454c-82f9-42f195a03c8f",
        "scrolled": true,
        "outputId": "f5dd3ad4-8119-4279-f2ba-6b5cbb0ab2fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ubuntu/wandb/run-20231221_040254-5nxwmli7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harperc/viggo-finetune/runs/5nxwmli7' target=\"_blank\">mixtral-viggo-finetune-2-2023-12-21-04-02</a></strong> to <a href='https://wandb.ai/harperc/viggo-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/harperc/viggo-finetune' target=\"_blank\">https://wandb.ai/harperc/viggo-finetune</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/harperc/viggo-finetune/runs/5nxwmli7' target=\"_blank\">https://wandb.ai/harperc/viggo-finetune/runs/5nxwmli7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 7:14:56, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.445100</td>\n",
              "      <td>0.365170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.354800</td>\n",
              "      <td>0.350717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.332600</td>\n",
              "      <td>0.325616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.322400</td>\n",
              "      <td>0.321214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.318800</td>\n",
              "      <td>0.319843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.319700</td>\n",
              "      <td>0.321574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.314600</td>\n",
              "      <td>0.323502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.331400</td>\n",
              "      <td>0.324546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.339000</td>\n",
              "      <td>0.323898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.308100</td>\n",
              "      <td>0.326155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.pyenv/versions/3.10.13/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.38985322761535646, metrics={'train_runtime': 26136.5823, 'train_samples_per_second': 0.077, 'train_steps_per_second': 0.019, 'total_flos': 1.9050365140992e+17, 'train_loss': 0.38985322761535646, 'epoch': 0.39})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "project = \"viggo-finetune\"\n",
        "base_model_name = \"mixtral\"\n",
        "run_name = base_model_name + \"-\" + project\n",
        "output_dir = \"./\" + run_name\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=5,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_checkpointing=True,\n",
        "        gradient_accumulation_steps=4,\n",
        "        max_steps=1000,\n",
        "        learning_rate=2.5e-5,\n",
        "        logging_steps=25,\n",
        "        fp16=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_dir=\"./logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=50,                # Save checkpoints every 50 steps\n",
        "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
        "        eval_steps=50,               # Evaluate and save checkpoints every 50 steps\n",
        "        do_eval=True,                # Perform evaluation at the end of training\n",
        "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "806802ac-eab6-4f22-a048-bd153e6745e1",
      "metadata": {
        "id": "806802ac-eab6-4f22-a048-bd153e6745e1"
      },
      "source": [
        "I cleared the output of the cell above because I stopped the training early, and it produced a long, ugly error message."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24beb8e2-1ea7-4c30-a8cc-37ff6b6e62b0",
      "metadata": {
        "id": "24beb8e2-1ea7-4c30-a8cc-37ff6b6e62b0"
      },
      "source": [
        "### 6. Drum Roll... Try the Trained Model!\n",
        "\n",
        "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`).\n",
        "\n",
        "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base Mixtral model from the Huggingface Hub:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538a7d9f-71f1-4b1e-bf96-e232ad302180",
      "metadata": {
        "id": "538a7d9f-71f1-4b1e-bf96-e232ad302180",
        "outputId": "d06890d5-70f4-4856-fb2a-4ee51e0c3f5f",
        "colab": {
          "referenced_widgets": [
            "dea124ca8e09445aa9f4905ab2c34717"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dea124ca8e09445aa9f4905ab2c34717",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,  # Mixtral, same as before\n",
        "    quantization_config=bnb_config,  # Same quantization config as before\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f4580e-1d9d-4c8d-b8d1-05cc7dee3bcf",
      "metadata": {
        "id": "f4f4580e-1d9d-4c8d-b8d1-05cc7dee3bcf"
      },
      "source": [
        "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6bdefc4-8b5b-4c16-82ff-ae54b70a50b4",
      "metadata": {
        "id": "d6bdefc4-8b5b-4c16-82ff-ae54b70a50b4"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"mixtral-viggo-finetune-2/checkpoint-500\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332c2771-3e84-405a-a780-1392bc6b737f",
      "metadata": {
        "id": "332c2771-3e84-405a-a780-1392bc6b737f"
      },
      "source": [
        "and run your inference!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f99ff63-728e-4cd7-a5a2-4a3580b00f84",
      "metadata": {
        "id": "3f99ff63-728e-4cd7-a5a2-4a3580b00f84"
      },
      "source": [
        "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better.\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240eaf08-96f9-434c-8d3a-a77939eaeab8",
      "metadata": {
        "id": "240eaf08-96f9-434c-8d3a-a77939eaeab8",
        "outputId": "436d4aa7-e336-49c1-bdba-5817f6247c0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
            "\n",
            "### Meaning representation:\n",
            "verify_attribute(name[Little Big Adventure], rating[not strong], genres[adventure], has_multiplayer[no])\n",
            "\n",
            "### Target sentence:\n",
            "What do you think of the action-adventure game\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
        "\n",
        "### Meaning representation:\n",
        "\"\"\"\n",
        "\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=50)[0], skip_special_tokens=True))\n",
        "\n",
        "Meaning Representation: verify_attribute(name[Little Big Adventure], rating[average], has_multiplayer[no], platforms[PlayStation])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a582c22a-3d76-49c6-be34-4cd386a23c6c",
      "metadata": {
        "id": "a582c22a-3d76-49c6-be34-4cd386a23c6c"
      },
      "source": [
        "### Sweet... it worked! The fine-tuned model now understands the meaning representation!\n",
        "\n",
        "It's not excellent, but I only fine-tuned it on 500 steps, and it hadn't yet converged. The longer you fine-tune, the better you can expect it to perform (just watch for overfitting).  \n",
        "\n",
        "I hope you enjoyed this tutorial on fine-tuning Mistral's 8x7B MoE model. If you have any questions, feel free to reach out to me on [X](https://x.com/harperscarroll) or on the [Discord channel](https://discord.gg/y9428NwTh3).\n",
        "\n",
        "ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™ ðŸ¤™"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}